{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ff93f4",
   "metadata": {},
   "source": [
    "Two methods are used for this task, the first is preprocessing the data to remove stop words as well as check against common positive words, the second is just to extract the positve scores of un processed text to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdbe85e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jackd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jackd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jackd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Activation, MaxPool1D, Conv1D, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543c4d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>cleaned_review_length</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>i wish would have gotten one earlier love it a...</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i ve learned this lesson again open the packag...</td>\n",
       "      <td>88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>it is so slow and lags find better option</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>roller ball stopped working within months of m...</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i like the color and size but it few days out ...</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17335</th>\n",
       "      <td>positive</td>\n",
       "      <td>i love this speaker and love can take it anywh...</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17336</th>\n",
       "      <td>positive</td>\n",
       "      <td>i use it in my house easy to connect and loud ...</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17337</th>\n",
       "      <td>positive</td>\n",
       "      <td>the bass is good and the battery is amazing mu...</td>\n",
       "      <td>41</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17338</th>\n",
       "      <td>positive</td>\n",
       "      <td>love it</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17339</th>\n",
       "      <td>neutral</td>\n",
       "      <td>mono speaker</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17340 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiments                                     cleaned_review  \\\n",
       "0       positive  i wish would have gotten one earlier love it a...   \n",
       "1        neutral  i ve learned this lesson again open the packag...   \n",
       "2        neutral          it is so slow and lags find better option   \n",
       "3        neutral  roller ball stopped working within months of m...   \n",
       "4        neutral  i like the color and size but it few days out ...   \n",
       "...          ...                                                ...   \n",
       "17335   positive  i love this speaker and love can take it anywh...   \n",
       "17336   positive  i use it in my house easy to connect and loud ...   \n",
       "17337   positive  the bass is good and the battery is amazing mu...   \n",
       "17338   positive                                            love it   \n",
       "17339    neutral                                       mono speaker   \n",
       "\n",
       "       cleaned_review_length  review_score  \n",
       "0                         19           5.0  \n",
       "1                         88           1.0  \n",
       "2                          9           2.0  \n",
       "3                         12           1.0  \n",
       "4                         21           1.0  \n",
       "...                      ...           ...  \n",
       "17335                     30           5.0  \n",
       "17336                     13           4.0  \n",
       "17337                     41           5.0  \n",
       "17338                      2           5.0  \n",
       "17339                      2           5.0  \n",
       "\n",
       "[17340 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data into a dataframe\n",
    "file = pd.read_csv(r'./data_assessment_2/data_for_sentiment_analyzis/amazon_reviews.csv')\n",
    "df = pd.DataFrame(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83302ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples =  9503\n",
      "Negative samplees =  1534\n",
      "Neutral samples =  6303\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples = ',len(df[df['sentiments'] == 'positive'])) #Check spread of data\n",
    "print('Negative samplees = ',len(df[df['sentiments'] == 'negative']))\n",
    "print('Neutral samples = ',len(df[df['sentiments'] == 'neutral']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01da811e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>cleaned_review_length</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>i wish would have gotten one earlier love it a...</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i ve learned this lesson again open the packag...</td>\n",
       "      <td>88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>it is so slow and lags find better option</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>roller ball stopped working within months of m...</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i like the color and size but it few days out ...</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17316</th>\n",
       "      <td>positive</td>\n",
       "      <td>i love this speaker and love can take it anywh...</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17317</th>\n",
       "      <td>positive</td>\n",
       "      <td>i use it in my house easy to connect and loud ...</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17318</th>\n",
       "      <td>positive</td>\n",
       "      <td>the bass is good and the battery is amazing mu...</td>\n",
       "      <td>41</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17319</th>\n",
       "      <td>positive</td>\n",
       "      <td>love it</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17320</th>\n",
       "      <td>neutral</td>\n",
       "      <td>mono speaker</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17321 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiments                                     cleaned_review  \\\n",
       "0       positive  i wish would have gotten one earlier love it a...   \n",
       "1        neutral  i ve learned this lesson again open the packag...   \n",
       "2        neutral          it is so slow and lags find better option   \n",
       "3        neutral  roller ball stopped working within months of m...   \n",
       "4        neutral  i like the color and size but it few days out ...   \n",
       "...          ...                                                ...   \n",
       "17316   positive  i love this speaker and love can take it anywh...   \n",
       "17317   positive  i use it in my house easy to connect and loud ...   \n",
       "17318   positive  the bass is good and the battery is amazing mu...   \n",
       "17319   positive                                            love it   \n",
       "17320    neutral                                       mono speaker   \n",
       "\n",
       "       cleaned_review_length  review_score  \n",
       "0                         19           5.0  \n",
       "1                         88           1.0  \n",
       "2                          9           2.0  \n",
       "3                         12           1.0  \n",
       "4                         21           1.0  \n",
       "...                      ...           ...  \n",
       "17316                     30           5.0  \n",
       "17317                     13           4.0  \n",
       "17318                     41           5.0  \n",
       "17319                      2           5.0  \n",
       "17320                      2           5.0  \n",
       "\n",
       "[17321 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DropNA does not catch blanks that need to be reomve for the feature extraction to work\n",
    "#Instead i drop all columns in the list\n",
    "df = df.drop([2085, 2894, 4333, 6043, 6841, 9526, 10063, 11388, 12912, 14435, 15481, 15557, 16222, 16495, 16502, 16529, 16802, 16911, 17281])\n",
    "#Remove blank reviews for tokenization\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6e0425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 17321/17321 [00:02<00:00, 7449.81it/s]\n"
     ]
    }
   ],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "positive_reviews = []\n",
    "negative_reviews = []\n",
    "neutral_reviews = []\n",
    "for i in tqdm(range(len(df))):#Loop through dataframe\n",
    "    if df.loc[i,'sentiments'] == 'positive':#check sentiment tag\n",
    "        pos_word = df.loc[i, 'cleaned_review']#selects the cleaned review text\n",
    "        pos_word = word_tokenize(pos_word) #tokenize reivew\n",
    "        pos_word = [word.lower() for word in pos_word] #converts tokens to lower case\n",
    "        pos_word = [word for word in pos_word if word not in stop_words] #remove stop words\n",
    "        positive_reviews.append(pos_word)#append preprocessed review\n",
    "    elif df.loc[i,'sentiments'] == 'negative':\n",
    "        neg_word = df.loc[i, 'cleaned_review']\n",
    "        neg_word = word_tokenize(neg_word)\n",
    "        neg_word = [word.lower() for word in neg_word]\n",
    "        neg_word = [word for word in neg_word if word not in stop_words]\n",
    "        negative_reviews.append(neg_word)\n",
    "    elif df.loc[i,'sentiments'] == 'neutral':\n",
    "        neutral_word = df.loc[i, 'cleaned_review']\n",
    "        neutral_word = word_tokenize(neutral_word)\n",
    "        neutral_word = [word.lower() for word in neutral_word]\n",
    "        neutral_word = [word for word in neutral_word if word not in stop_words]\n",
    "        neutral_reviews.append(neutral_word)\n",
    "    else:\n",
    "        print(\"Unrecgonised tag at index = \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de49a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posWords = []\n",
    "all_negWords = []\n",
    "all_neutralWords = []\n",
    "\n",
    "for wordList in positive_reviews:\n",
    "    all_posWords += wordList\n",
    "    \n",
    "for wordList in negative_reviews:\n",
    "    all_negWords += wordList\n",
    "    \n",
    "for wordList in neutral_reviews:\n",
    "    all_neutralWords += wordList\n",
    "\n",
    "positive_fd = nltk.FreqDist(all_posWords)#frequency distribution for review words\n",
    "negative_fd = nltk.FreqDist(all_negWords)\n",
    "neutral_fd = nltk.FreqDist(all_neutralWords)\n",
    "\n",
    "most_common_pos = {word for word, count in positive_fd.most_common(100)}#selects most common words in each dist\n",
    "most_common_neg = {word for word, count in negative_fd.most_common(100)}\n",
    "most_common_neutral = {word for word, count in neutral_fd.most_common(100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924b2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "def feat_extract1(text):#extracts sentiment of each review\n",
    "    features = []\n",
    "    wordcount = 0\n",
    "    compound_scores = list()\n",
    "    positive_scores = list()\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            if word.lower() in most_common_pos:\n",
    "                wordcount +=1\n",
    "        compound_scores.append(sia.polarity_scores(sentence)[\"compound\"])\n",
    "        positive_scores.append(sia.polarity_scores(sentence)[\"pos\"])#gets compound and postive score for prediction\n",
    "    features.append(mean(compound_scores) +1)\n",
    "    features.append(mean(positive_scores))\n",
    "    features.append(wordcount)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c57a8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 17321/17321 [00:09<00:00, 1740.20it/s]\n"
     ]
    }
   ],
   "source": [
    "pos_features = []\n",
    "neg_features = []\n",
    "neutral_features = []\n",
    "pos_labels = []\n",
    "neg_labels = []\n",
    "neutral_labels = []\n",
    "\n",
    "#Gather data for prediciton\n",
    "for i in tqdm(range(len(df))):\n",
    "    if df.loc[i, 'sentiments'] == 'positive':\n",
    "        word = df.loc[i, 'cleaned_review']\n",
    "        pos_features.append(feat_extract1(word))\n",
    "        pos_labels.append('positive')\n",
    "    elif df.loc[i, 'sentiments'] == 'negative':\n",
    "        word = df.loc[i, 'cleaned_review']\n",
    "        neg_features.append(feat_extract1(word))\n",
    "        neg_labels.append('negative')\n",
    "    elif df.loc[i, 'sentiments'] == 'neutral':\n",
    "        word = df.loc[i, 'cleaned_review']\n",
    "        neutral_features.append(feat_extract1(word))\n",
    "        neutral_labels.append('neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a804036",
   "metadata": {},
   "source": [
    "To split the data i will split all the tags to a 70 30% split then add them to one big train list\n",
    "This is to advoid any bias in the training with one sample having little to no representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd7fb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the tree reviews in to 70 30 train test as mention above\n",
    "pos_train_X, pos_test_X, pos_train_y, pos_test_y = train_test_split(pos_features, pos_labels, test_size=0.3)\n",
    "neg_train_X, neg_test_X, neg_train_y, neg_test_y = train_test_split(neg_features, neg_labels, test_size=0.3)\n",
    "neutral_train_X, neutral_test_X, neutral_train_y, neutral_test_y = train_test_split(neutral_features, neutral_labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281a0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []#gathers each in to a central feature location\n",
    "train_features.extend(pos_train_X)\n",
    "train_features.extend(neg_train_X)\n",
    "train_features.extend(neutral_train_X)\n",
    "\n",
    "train_labels = []\n",
    "train_labels.extend(pos_train_y)\n",
    "train_labels.extend(neg_train_y)\n",
    "train_labels.extend(neutral_train_y)\n",
    "\n",
    "test_features = []\n",
    "test_features.extend(pos_test_X)\n",
    "test_features.extend(neg_test_X)\n",
    "test_features.extend(neutral_test_X)\n",
    "\n",
    "test_labels = []\n",
    "test_labels.extend(pos_test_y)\n",
    "test_labels.extend(neg_test_y)\n",
    "test_labels.extend(neutral_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb3bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(train_features, train_labels))\n",
    "random.shuffle(c)\n",
    "train_features, train_labels = zip(*c)\n",
    "\n",
    "c = list(zip(test_features, test_labels))\n",
    "random.shuffle(c)\n",
    "test_features, test_labels = zip(*c)\n",
    "\n",
    "#Shuffles the data and labels keeping each postion matched so it can be used to evalute the classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "467d4ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)#conver to np arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d37aa6e",
   "metadata": {},
   "source": [
    "Hyper Parameter Training can take a while to run so dont run it everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4c80388",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28256/4082895849.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gamma'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kernel'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rbf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m#set param to test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mTune_SVC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#establish classifier and params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mTune_SVC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#fits data to run on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best Parameters:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTune_SVC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    872\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1388\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    819\u001b[0m                     )\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param = {'C': [1, 10, 100], 'gamma': [0.001, 0.0001], 'kernel': ['linear', 'rbf']} #set param to test\n",
    "Tune_SVC = GridSearchCV(estimator=SVC(), param_grid=param, cv=10, scoring='accuracy') #establish classifier and params\n",
    "Tune_SVC.fit(train_features, train_labels)#fits data to run on\n",
    "print(\"Best Parameters:\")\n",
    "print(Tune_SVC.best_estimator_)\n",
    "\n",
    "df_SVC = pd.DataFrame({'parameters':Tune_SVC.cv_results_[\"params\"], 'Mean_Accuracy':Tune_SVC.cv_results_[\"mean_test_score\"]})\n",
    "df_SVC#gathers the data into a daatframe for easy viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ffa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=1, gamma=0.001, kernel='linear')#build and test classifier\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "predict = clf.predict(test_features)\n",
    "\n",
    "matrix = confusion_matrix(test_labels, predict)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix= matrix)\n",
    "\n",
    "print('Prediction accuracy =', accuracy_score(test_labels, predict))\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa4b340",
   "metadata": {},
   "source": [
    "Second method - Count vecotrize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7097b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = CountVectorizer(max_features=100)#counter vector of reviews\n",
    "X = matrix.fit_transform(df['cleaned_review']).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5125fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lables = df['sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eab7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, lables, test_size=0.3)#split into test train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = SVC(C=1, gamma=0.001, kernel='linear')#classifier for second method\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "predict2 = clf2.predict(X_test)\n",
    "\n",
    "matrix2 = confusion_matrix(y_test, predict2)\n",
    "cm_display2 = ConfusionMatrixDisplay(confusion_matrix= matrix2)\n",
    "\n",
    "print('Prediction accuracy =', accuracy_score(y_test, predict2))\n",
    "cm_display2.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb19cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "User_Query = input(\"What review would you like to check \")#ask user for query they wish to check sentiment for\n",
    "user_features = feat_extract1(User_Query)\n",
    "user_features = np.array(user_features)\n",
    "user_features = user_features.reshape(1,-1)\n",
    "prediction = clf.predict(user_features)\n",
    "print(\"The review you entered is \",prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d8036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c21b577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned_review'].values\n",
    "Y = df['sentiments'].values\n",
    "\n",
    "y = []\n",
    "for i in range(len(Y)):\n",
    "    if Y[i] == 'positive':\n",
    "        y.append(0)\n",
    "    elif Y[i] == 'neutral':\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00cf53e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "y_test = np.asarray(y_test).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82310b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "x_train = tokenizer.texts_to_sequences(X_train)\n",
    "x_test = tokenizer.texts_to_sequences(X_test)\n",
    "vocab = len(tokenizer.word_index) + 1\n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=100)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc47b1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          844500    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 96, 64)            32064     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 19, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 15, 128)           41088     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 3, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3, 40)             5160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3, 1)              41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 922,853\n",
      "Trainable params: 922,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab, output_dim= 100, input_length= 100))\n",
    "model.add(Conv1D(64,5, activation='relu'))\n",
    "model.add(MaxPool1D(5))\n",
    "model.add(Conv1D(128,5, activation='relu'))\n",
    "model.add(MaxPool1D(5))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84ae3dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "758/758 [==============================] - 9s 11ms/step - loss: 0.5931 - accuracy: 0.6627\n",
      "Epoch 2/20\n",
      "758/758 [==============================] - 9s 12ms/step - loss: 0.5438 - accuracy: 0.7011\n",
      "Epoch 3/20\n",
      "758/758 [==============================] - 8s 11ms/step - loss: 0.5034 - accuracy: 0.7248\n",
      "Epoch 4/20\n",
      "758/758 [==============================] - 9s 11ms/step - loss: 0.4471 - accuracy: 0.7561\n",
      "Epoch 5/20\n",
      "758/758 [==============================] - 9s 11ms/step - loss: 0.3951 - accuracy: 0.7811\n",
      "Epoch 6/20\n",
      "758/758 [==============================] - 9s 11ms/step - loss: 0.3718 - accuracy: 0.7895\n",
      "Epoch 7/20\n",
      "758/758 [==============================] - 9s 12ms/step - loss: 0.3608 - accuracy: 0.7942\n",
      "Epoch 8/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3571 - accuracy: 0.7951\n",
      "Epoch 9/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3558 - accuracy: 0.7960\n",
      "Epoch 10/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3543 - accuracy: 0.7962\n",
      "Epoch 11/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3492 - accuracy: 0.7981\n",
      "Epoch 12/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3467 - accuracy: 0.7994\n",
      "Epoch 13/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3516 - accuracy: 0.7969\n",
      "Epoch 14/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3476 - accuracy: 0.7992\n",
      "Epoch 15/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3443 - accuracy: 0.8001\n",
      "Epoch 16/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3453 - accuracy: 0.7993\n",
      "Epoch 17/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3450 - accuracy: 0.7997\n",
      "Epoch 18/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3442 - accuracy: 0.7998\n",
      "Epoch 19/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3411 - accuracy: 0.8010\n",
      "Epoch 20/20\n",
      "758/758 [==============================] - 8s 10ms/step - loss: 0.3442 - accuracy: 0.7998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241c88824c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, verbose=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e571b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1s 3ms/step - loss: 0.9791 - accuracy: 0.7021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9790781140327454, 0.7020716071128845]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a9d7739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 3ms/step - loss: 0.9791 - accuracy: 0.7021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9790781140327454, 0.7020716071128845]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43edad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
